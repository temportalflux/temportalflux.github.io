---
title: "Sensor Expo Demo"
order: 4
date: 2017-07-15
excerpt: "A demonstration of using wireless sensors in Unity"

header:
  image: /assets/projects/sensorconnect_demo/images/teaser.png
  teaser: /assets/projects/sensorconnect_demo/images/teaser.png

layout: home
language: "Unity, C#"
year: "2017"
portfolio: "true"

sidebar:
  - title: "Description"
    text: "A demonstration of using wireless sensors in Unity"
  - title: "Timeframe"
    text: "July-August 2017"
  - title: "Contribution"
    text: "Programming Intern"
  - title: "Outcomes"
    text: "Unity interaction with unsupported input types. Responsive simulation effects with user input."
  - title: "Links"
  - button: Application
    link: 
---

While assisting in the continued development of *[SensorConnect](/projects/05_sensorconnect)*, I was tasked with the creation of a interactable demonstration. This interactive game demo needed to take the input from various LORD Microstrain sensors, and convert that input into something the user can see/experience. This resulted in the creation of a demonstration later used for a Google expo.

While virtual unusable without the LORD sensors, I was allowed to record a demontration of the game-simulation and take the source with me.

<video style="width:100%;" controls>
  <source src="{{ site.url }}/assets/projects/sensorconnect_demo/Reel.mp4" type="video/mp4">
</video>
